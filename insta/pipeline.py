from typing import Callable, Tuple, List, Dict, Generator
from collections import namedtuple

from dataclasses import asdict
from itertools import count

from torch.multiprocessing import (
    Process,
    Queue,
)

from insta.configs import (
    DEFAULT_BROWSER_CONFIG,
    DEFAULT_AGENT_CONFIG,
    DEFAULT_JUDGE_CONFIG,
    DEFAULT_TASK_PROPOSER_CONFIG,
    BrowserConfig,
    AgentConfig,
    JudgeConfig,
    TaskProposerConfig,
    get_browser_config,
    get_agent_config,
    get_judge_config,
    get_task_proposer_config,
)

from insta.gym_env import (
    InstaEnv,
    InstaEnvStepOutput
)

from insta.agent import (
    BrowserAgent,
    NULL_ACTION
)

from insta.judge import (
    BrowserJudge,
    NULL_JUDGMENT
)

from insta.task_proposer import (
    BrowserTaskProposer,
    NULL_TASK_PROPOSAL
)

from insta.utils import (
    prune_observation,
    METADATA_KEYS,
    BrowserStatus,
    safe_call
)


import torch
import random

import time
import tqdm
import json
import os


DEFAULT_OBSERVATIONS_DIR = "data/observations"
DEFAULT_SCREENSHOT_DIR = "data/screenshots"
DEFAULT_ACTIONS_DIR = "data/actions"

DEFAULT_JUDGMENTS_DIR = None
DEFAULT_TASK_PROPOSALS_DIR = None

DEFAULT_AGENT_RESPONSE_KEY = "response"
DEFAULT_JUDGE_RESPONSE_KEY = "response"

DEFAULT_MAX_ACTIONS = 30
DEFAULT_SKIP_FINISHED = False
DEFAULT_PRUNE_OBSERVATIONS = False

DEFAULT_ADD_STEPS_TO_AGENT = False
DEFAULT_ADD_CRITERIA_TO_AGENT = False

DEFAULT_ADD_STEPS_TO_JUDGE = False
DEFAULT_ADD_CRITERIA_TO_JUDGE = False

DEFAULT_ADD_STEPS_TO_TASK_PROPOSER = False
DEFAULT_ADD_CRITERIA_TO_TASK_PROPOSER = False

AGENT_EXPLORATION_TEMPLATE = (
    "Thoroughly explore this website by navigating pages, highlight interesting content we find, and list what real users can accomplish on this website."
)

JUDGE_EXPLORATION_TEMPLATE = (
    "The agent must thoroughly explore this website by navigating pages, highlight interesting content it finds, and list what real users can accomplish on this website."
)

TASK_PROPOSER_EXPLORATION_TEMPLATE = (
    "The agent must thoroughly explore this website by navigating pages, highlight interesting content it finds, and list what real users can accomplish on this website."
)

AGENT_STEPS_TEMPLATE = (
    "{instruction}\n\nTo complete the task, we should consider these steps:\n{steps}"
)

JUDGE_STEPS_TEMPLATE = (
    "{instruction}\n\nThe agent must follow these steps:\n{steps}"
)

TASK_PROPOSER_STEPS_TEMPLATE = (
    "{instruction}\n\nThe agent must follow these steps:\n{steps}"
)

AGENT_CRITERIA_TEMPLATE = (
    "{instruction}\n\nTo complete the task, we should consider these criteria:\n{criteria}"
)

JUDGE_CRITERIA_TEMPLATE = (
    "{instruction}\n\nThe agent must satisfy these criteria:\n{criteria}"
)

TASK_PROPOSER_CRITERIA_TEMPLATE = (
    "{instruction}\n\nThe agent must satisfy these criteria:\n{criteria}"
)

DEFAULT_SEED = 0
DEFAULT_RANK = 0
DEFAULT_WORLD_SIZE = 1

DEFAULT_NUM_AGENTS = 8
DEFAULT_PLAYWRIGHT_WORKERS = 8
DEFAULT_RETURN_TRAJECTORIES = False

DEFAULT_REWARD = 0.0
DEFAULT_DONE = False
DEFAULT_TRUNCATED = False
DEFAULT_INFO = {}


InstaPipelineOutput = namedtuple(
    "InstaPipelineOutput",
    ["observations", "actions", "judgment", "task_proposal"]
)


def generate_trajectory(
    browser: InstaEnv | BrowserConfig,
    agent: BrowserAgent | AgentConfig,
    judge: BrowserJudge | JudgeConfig = None,
    task_proposer: BrowserTaskProposer | TaskProposerConfig = None,
    url: str = None, instruction: str = None,
    agent_instruction: str = None,
    judge_instruction: str = None,
    task_proposer_instruction: str = None,
    max_actions: int = DEFAULT_MAX_ACTIONS,
    agent_response_key: str = DEFAULT_AGENT_RESPONSE_KEY,
    judge_response_key: str = DEFAULT_JUDGE_RESPONSE_KEY,
) -> Tuple[List[Dict], List[Dict], Dict]:
    """Attempt a web navigation task using the LLM agent, and return the
    observations and actions along the trajectory for later processing.

    Arguments:

    env: InstaEnv | BrowserConfig
        The web navigation environment running Playwright.

    agent: BrowserAgent | AgentConfig
        The LLM agent to use for the task.

    judge: BrowserJudge | JudgeConfig
        The LLM judge to evaluate the trajectory.

    task_proposer: BrowserTaskProposer | TaskProposerConfig
        The LLM task proposer to generate tasks for the agent to complete.

    url: str
        Starting URL for the agent.

    instruction: str
        Specific instruction for the agent.

    max_actions: int
        Maximum number of actions per task.

    Returns:

    Tuple[List[Dict], List[Dict], Dict]
        Tuple containing observations, actions, and judgment for the trajectory
        generated by running the agent with an instruction.
    
    """

    if isinstance(browser, BrowserConfig):

        browser = InstaEnv(
            config = browser
        )

    if isinstance(agent, AgentConfig):

        agent = BrowserAgent(
            config = agent
        )

    if judge is not None and \
            isinstance(judge, JudgeConfig):

        judge = BrowserJudge(
            config = judge
        )

    if task_proposer is not None and \
            isinstance(task_proposer, TaskProposerConfig):

        task_proposer = BrowserTaskProposer(
            config = task_proposer
        )

    agent_instruction = (
        agent_instruction or 
        instruction or 
        AGENT_EXPLORATION_TEMPLATE.format(
            website = url
        )
    )

    judge_instruction = (
        judge_instruction or
        instruction or 
        JUDGE_EXPLORATION_TEMPLATE.format(
            website = url
        )
    )

    task_proposer_instruction = (
        task_proposer_instruction or
        instruction or 
        TASK_PROPOSER_EXPLORATION_TEMPLATE.format(
            website = url
        )
    )

    observations = []
    actions = []
    last_action = NULL_ACTION

    for timestep in range(max_actions):

        outputs = None

        if last_action is not NULL_ACTION:

            agent.push_action(
                response = last_action.response
            )

            outputs = browser.step(
                action = last_action
            )

        elif timestep == 0:

            agent.reset()

            outputs = browser.reset(
                url = url
            )

        else: outputs = InstaEnvStepOutput(
            observation = browser.get_obs(),
            reward = DEFAULT_REWARD,
            done = DEFAULT_DONE,
            truncated = DEFAULT_TRUNCATED,
            info = DEFAULT_INFO
        )

        is_finished = outputs is None or (
            isinstance(outputs, InstaEnvStepOutput)
            and outputs.done
        )

        if is_finished:
            
            break

        obs = outputs.observation

        for key, value in (obs.metadata or {}).items():

            obs.metadata[key] = {
                key: value.get(key)
                for key in METADATA_KEYS
            } 

        observations.append({
            "current_url": obs.current_url,
            "processed_text": obs.processed_text,
            "raw_html": obs.raw_html,
            "screenshot": obs.screenshot,
            "metadata": obs.metadata
        })

        agent.pop_observation()
        
        last_action = agent(
            observation = obs.processed_text,
            instruction = agent_instruction,
            current_url = obs.current_url
        )

        function_calls = [
            {"dotpath": x.dotpath, "args": x.args}
            for x in last_action.function_calls
        ]

        actions.append({
            "function_calls": function_calls,
            "response": last_action.response,
            "matched_response": last_action.matched_response
        })

    is_truncated = outputs is None or (
        isinstance(outputs, InstaEnvStepOutput)
        and outputs.truncated
    )

    if is_truncated:

        raise RuntimeError(
            "Failed to generate trajectory:\n{}\n\n"
            .format(outputs)
        )

    judgment = {}

    if judge is not None:

        judgment = judge(
            observations = [
                x["processed_text"]
                for x in observations
            ],
            actions = [
                x[agent_response_key]
                for x in actions
            ],
            instruction = judge_instruction
        )

        judgment = {
            "success": judgment.success,
            "efficiency": judgment.efficiency,
            "self_correction": judgment.self_correction,
            "response": judgment.response,
            "matched_response": judgment.matched_response,
        }

    task_proposal = {}

    if task_proposer is not None:

        task_proposal = task_proposer(
            instruction = task_proposer_instruction,
            website = url,
            observations = [
                x["processed_text"]
                for x in observations
            ],
            actions = [
                x[agent_response_key]
                for x in actions
            ],
            judgment = (
                judgment[
                    judge_response_key
                ]
            ),
        )

        task_proposal = {
            "proposed_task": task_proposal.proposed_task,
            "steps": task_proposal.steps,
            "criteria": task_proposal.criteria,
            "response": task_proposal.response,
            "matched_response": task_proposal.matched_response,
        }

    return observations, actions, judgment, task_proposal


DEFAULT_WEBSITE = "duckduckgo.com"
DEFAULT_STEPS = []
DEFAULT_CRITERIA = []


def iter_trajectories(
    dataset: List[Dict[str, str]],
    browser: InstaEnv | BrowserConfig,
    agent: BrowserAgent | AgentConfig,
    judge: BrowserJudge | JudgeConfig = None,
    task_proposer: BrowserTaskProposer | TaskProposerConfig = None,
    seed: int = DEFAULT_SEED,
    rank: int = DEFAULT_RANK,
    world_size: int = DEFAULT_WORLD_SIZE,
    observations_dir: str = DEFAULT_OBSERVATIONS_DIR,
    screenshot_dir: str = DEFAULT_SCREENSHOT_DIR,
    actions_dir: str = DEFAULT_ACTIONS_DIR,
    judgments_dir: str = DEFAULT_JUDGMENTS_DIR,
    task_proposals_dir: str = DEFAULT_TASK_PROPOSALS_DIR,
    max_actions: int = DEFAULT_MAX_ACTIONS,
    agent_response_key: str = DEFAULT_AGENT_RESPONSE_KEY,
    judge_response_key: str = DEFAULT_JUDGE_RESPONSE_KEY,
    skip_finished: bool = DEFAULT_SKIP_FINISHED,
    prune_observations: bool = DEFAULT_PRUNE_OBSERVATIONS,
    add_steps_to_agent: bool = DEFAULT_ADD_STEPS_TO_AGENT,
    add_criteria_to_agent: bool = DEFAULT_ADD_CRITERIA_TO_AGENT,
    add_steps_to_judge: bool = DEFAULT_ADD_STEPS_TO_JUDGE,
    add_criteria_to_judge: bool = DEFAULT_ADD_CRITERIA_TO_JUDGE,
    add_steps_to_task_proposer: bool = DEFAULT_ADD_STEPS_TO_TASK_PROPOSER,
    add_criteria_to_task_proposer: bool = DEFAULT_ADD_CRITERIA_TO_TASK_PROPOSER,
) -> Generator[InstaPipelineOutput, None, None]:
    """Run the InSTA pipeline for internet-scale data collection, and yield
    the observations, actions, and judgments for each task.

    Arguments:

    dataset: List[Dict[str, str]]
        Override the default dataset, and run the pipeline on custom tasks,
        each entry must be a dictionary with keys "domain" and "task".

    agent: BrowserAgent | AgentConfig
        The LLM agent to use for the task.

    judge: BrowserJudge | JudgeConfig
        The LLM judge to evaluate the trajectory.

    browser: InstaEnv | BrowserConfig
        The web navigation environment running Playwright.

    rank: int
        Rank of the process.

    world_size: int
        Number of data collection processes.

    seed: int
        Seed for the dataset.

    observations_dir: str
        Directory to save observations.

    screenshot_dir: str
        Directory to save screenshots.

    actions_dir: str
        Directory to save actions.

    judgments_dir: str
        Directory to save judgments.

    max_actions: int
        Maximum number of actions per task.

    skip_finished: bool
        Whether to skip tasks that are already attempted.

    prune_observations: bool
        Whether to prune observations before saving.

    Returns:

    Generator[InstaPipelineOutput, None, None]
        Generator for the observations, actions, and judgments for each task, 
        which are saved to disk for later processing.
    
    """

    if isinstance(browser, BrowserConfig):

        browser = InstaEnv(
            config = browser
        )

    if isinstance(agent, AgentConfig):

        agent = BrowserAgent(
            config = agent
        )

    if judge is not None and \
            isinstance(judge, JudgeConfig):

        judge = BrowserJudge(
            config = judge
        )

    if task_proposer is not None and \
            isinstance(task_proposer, TaskProposerConfig):

        task_proposer = BrowserTaskProposer(
            config = task_proposer
        )

    if observations_dir is not None:

        os.makedirs(
            observations_dir, 
            exist_ok = True
        )

    if screenshot_dir is not None:

        os.makedirs(
            screenshot_dir, 
            exist_ok = True
        )

    if actions_dir is not None:

        os.makedirs(
            actions_dir, 
            exist_ok = True
        )

    if judgments_dir is not None:

        os.makedirs(
            judgments_dir, 
            exist_ok = True
        )

    if task_proposals_dir is not None:

        os.makedirs(
            task_proposals_dir, 
            exist_ok = True
        )

    dataset_ids = list(range(len(dataset)))

    random.seed(seed)
    random.shuffle(dataset_ids)

    dataset_ids = dataset_ids[
        rank::world_size
    ]

    progress_bar = tqdm.tqdm(
        dataset_ids, desc = "Processing",
        dynamic_ncols = True
    )

    for example_id in progress_bar:

        example_dict = dataset[example_id]

        domain = example_dict.get(
            "website", example_dict.get(
                "domain", DEFAULT_WEBSITE
            )
        )

        instruction = example_dict.get(
            "instruction", example_dict.get("task")
        )

        agent_instruction = example_dict.get(
            "agent_instruction", example_dict.get(
                "agent_task", instruction
            )
        )

        judge_instruction = example_dict.get(
            "judge_instruction", example_dict.get(
                "judge_task", instruction
            )
        )

        task_proposer_instruction = example_dict.get(
            "task_proposer_instruction", example_dict.get(
                "task_proposer_task", instruction
            )
        )

        identifier = example_dict.get(
            "identifier", domain
        )

        steps = example_dict.get(
            "steps", DEFAULT_STEPS
        )

        criteria = example_dict.get(
            "criteria", DEFAULT_CRITERIA
        )

        format_steps = "\n".join(
            "{n}. {part}".format(n = idx + 1, part = part)
            for idx, part in enumerate(steps)
        )

        format_criteria = "\n".join(
            "{n}. {part}".format(n = idx + 1, part = part)
            for idx, part in enumerate(criteria)
        )

        if add_steps_to_agent and len(steps) > 0:

            agent_instruction = AGENT_STEPS_TEMPLATE.format(
                instruction = agent_instruction,
                steps = format_steps
            )

        if add_criteria_to_agent and len(criteria) > 0:

            agent_instruction = AGENT_CRITERIA_TEMPLATE.format(
                instruction = agent_instruction,
                criteria = format_criteria
            )

        if add_steps_to_judge and len(steps) > 0:

            judge_instruction = JUDGE_STEPS_TEMPLATE.format(
                instruction = judge_instruction,
                steps = format_steps
            )

        if add_criteria_to_judge and len(criteria) > 0:

            judge_instruction = JUDGE_CRITERIA_TEMPLATE.format(
                instruction = judge_instruction,
                criteria = format_criteria
            )

        if add_steps_to_task_proposer and len(steps) > 0:

            task_proposer_instruction = TASK_PROPOSER_STEPS_TEMPLATE.format(
                instruction = task_proposer_instruction,
                steps = format_steps
            )

        if add_criteria_to_task_proposer and len(criteria) > 0:

            task_proposer_instruction = TASK_PROPOSER_CRITERIA_TEMPLATE.format(
                instruction = task_proposer_instruction,
                criteria = format_criteria
            )

        progress_bar.set_description(
            "Processing: {}".format(
                identifier
            )
        )

        if observations_dir is not None:

            observations_path = os.path.join(
                observations_dir,
                "{}.json".format(identifier)
            )

        if actions_dir is not None:

            actions_path = os.path.join(
                actions_dir,
                "{}.json".format(identifier)
            )

        if judgments_dir is not None:

            judgment_path = os.path.join(
                judgments_dir,
                "{}.json".format(identifier)
            )

        if task_proposals_dir is not None:

            task_proposal_path = os.path.join(
                task_proposals_dir,
                "{}.json".format(identifier)
            )

        if screenshot_dir is not None:

            screenshot_domain_dir = os.path.join(
                screenshot_dir,
                "{}".format(identifier)
            )

            os.makedirs(
                screenshot_domain_dir,
                exist_ok = True
            )

        judgment_exists = (
            judgments_dir is not None
            and os.path.exists(judgment_path)
        )

        task_proposal_exists = (
            task_proposals_dir is not None
            and os.path.exists(task_proposal_path)
        )

        skip_this_task = (
            skip_finished
            and judgment_exists
            and task_proposal_exists
        )

        if skip_this_task:

            continue

        has_protocol = (
            domain.startswith("http://")
            or domain.startswith("https://")
        )

        if not has_protocol:

            url = "http://{domain}".format(
                domain = domain
            )

        else: url = domain
        
        trajectory = safe_call(
            generate_trajectory,
            browser = browser, agent = agent, judge = judge,
            task_proposer = task_proposer,
            url = url, instruction = instruction,
            agent_instruction = agent_instruction,
            judge_instruction = judge_instruction,
            task_proposer_instruction = task_proposer_instruction,
            max_actions = max_actions,
            agent_response_key = agent_response_key,
            judge_response_key = judge_response_key,
            catch_errors = True,
            log_errors = True,
            max_errors = 1,
        )

        observations, actions, judgment, task_proposal = [], [], {}, {}

        if trajectory is not BrowserStatus.ERROR:

            observations, actions, judgment, task_proposal = trajectory

        for step_idx, observation in enumerate(observations):

            if screenshot_dir is not None and \
                    observation.get("screenshot") is not None:

                screenshot_path = os.path.join(
                    screenshot_domain_dir,
                    "screenshot_{:02d}.jpg"
                    .format(step_idx)
                )

                screenshot = observation.pop(
                    "screenshot"
                )

                screenshot.convert("RGB").save(
                    screenshot_path
                )

                observation["screenshot_path"] = (
                    screenshot_path
                )

            if prune_observations:
                
                observations[step_idx] = (
                    prune_observation(
                        observation
                    )
                )

        observations_valid = (
            observations is not None and 
            len(observations) > 0
        )

        actions_valid = (
            actions is not None and 
            len(actions) > 0
        )

        judgment_valid = (
            judgment is not None and 
            len(judgment) > 0
        )

        task_proposal_valid = (
            task_proposal is not None and 
            len(task_proposal) > 0
        )

        trajectory_valid = (
            observations_valid and actions_valid and 
            (judgment_valid or judge is None) and
            (task_proposal_valid or task_proposer is None)
        )

        if observations_valid and \
                observations_dir is not None:
                
            with open(observations_path, "w") as file:
                
                json.dump(
                    observations, 
                    file,
                    indent = 4
                )

        if actions_valid and \
                actions_dir is not None:

            with open(actions_path, "w") as file:
                
                json.dump(
                    actions, 
                    file,
                    indent = 4
                )

        if judgment_valid and \
                judgments_dir is not None:

            with open(judgment_path, "w") as file:
                
                json.dump(
                    judgment, 
                    file,
                    indent = 4
                )

        if task_proposal_valid and \
                task_proposals_dir is not None:

            with open(task_proposal_path, "w") as file:
                
                json.dump(
                    task_proposal, 
                    file,
                    indent = 4
                )

        yield InstaPipelineOutput(
            observations = observations,
            actions = actions,
            judgment = judgment,
            task_proposal = task_proposal
        )


def list_trajectories(
    dataset: List[Dict[str, str]],
    browser: InstaEnv | BrowserConfig,
    agent: BrowserAgent | AgentConfig,
    judge: BrowserJudge | JudgeConfig = None,
    task_proposer: BrowserTaskProposer | TaskProposerConfig = None,
    seed: int = DEFAULT_SEED,
    rank: int = DEFAULT_RANK,
    world_size: int = DEFAULT_WORLD_SIZE,
    observations_dir: str = DEFAULT_OBSERVATIONS_DIR,
    screenshot_dir: str = DEFAULT_SCREENSHOT_DIR,
    actions_dir: str = DEFAULT_ACTIONS_DIR,
    judgments_dir: str = DEFAULT_JUDGMENTS_DIR,
    task_proposals_dir: str = DEFAULT_TASK_PROPOSALS_DIR,
    max_actions: int = DEFAULT_MAX_ACTIONS,
    agent_response_key: str = DEFAULT_AGENT_RESPONSE_KEY,
    judge_response_key: str = DEFAULT_JUDGE_RESPONSE_KEY,
    skip_finished: bool = DEFAULT_SKIP_FINISHED,
    prune_observations: bool = DEFAULT_PRUNE_OBSERVATIONS,
    add_steps_to_agent: bool = DEFAULT_ADD_STEPS_TO_AGENT,
    add_criteria_to_agent: bool = DEFAULT_ADD_CRITERIA_TO_AGENT,
    add_steps_to_judge: bool = DEFAULT_ADD_STEPS_TO_JUDGE,
    add_criteria_to_judge: bool = DEFAULT_ADD_CRITERIA_TO_JUDGE,
    add_steps_to_task_proposer: bool = DEFAULT_ADD_STEPS_TO_TASK_PROPOSER,
    add_criteria_to_task_proposer: bool = DEFAULT_ADD_CRITERIA_TO_TASK_PROPOSER,
) -> List[InstaPipelineOutput]:
    """Run the InSTA pipeline for internet-scale data collection, and list
    the observations, actions, and judgments for each task.

    Arguments:

    dataset: List[Dict[str, str]]
        Override the default dataset, and run the pipeline on custom tasks,
        each entry must be a dictionary with keys "domain" and "task".

    agent: BrowserAgent | AgentConfig
        The LLM agent to use for the task.

    judge: BrowserJudge | JudgeConfig
        The LLM judge to evaluate the trajectory.

    browser: InstaEnv | BrowserConfig
        The web navigation environment running Playwright.

    rank: int
        Rank of the process.

    world_size: int
        Number of data collection processes.

    seed: int
        Seed for the dataset.

    observations_dir: str
        Directory to save observations.

    screenshot_dir: str
        Directory to save screenshots.

    actions_dir: str
        Directory to save actions.

    judgments_dir: str
        Directory to save judgments.

    max_actions: int
        Maximum number of actions per task.

    skip_finished: bool
        Whether to skip tasks that are already attempted.

    prune_observations: bool
        Whether to prune observations before saving.

    Returns:

    List[InstaPipelineOutput]
        List with observations, actions, and judgments for each task, 
        which are saved to disk for later processing.
    
    """

    return list(iter_trajectories(
        dataset = dataset, browser = browser,
        agent = agent, judge = judge,
        task_proposer = task_proposer,
        seed = seed, rank = rank, world_size = world_size,
        observations_dir = observations_dir,
        screenshot_dir = screenshot_dir,
        actions_dir = actions_dir,
        judgments_dir = judgments_dir,
        task_proposals_dir = task_proposals_dir,
        max_actions = max_actions,
        agent_response_key = agent_response_key,
        judge_response_key = judge_response_key,
        skip_finished = skip_finished,
        prune_observations = prune_observations,
        add_steps_to_agent = add_steps_to_agent,
        add_criteria_to_agent = add_criteria_to_agent,
        add_steps_to_judge = add_steps_to_judge,
        add_criteria_to_judge = add_criteria_to_judge,
        add_steps_to_task_proposer = add_steps_to_task_proposer,
        add_criteria_to_task_proposer = add_criteria_to_task_proposer,
    ))


def save_trajectories(
    dataset: List[Dict[str, str]],
    browser: InstaEnv | BrowserConfig,
    agent: BrowserAgent | AgentConfig,
    judge: BrowserJudge | JudgeConfig = None,
    task_proposer: BrowserTaskProposer | TaskProposerConfig = None,
    seed: int = DEFAULT_SEED,
    rank: int = DEFAULT_RANK,
    world_size: int = DEFAULT_WORLD_SIZE,
    observations_dir: str = DEFAULT_OBSERVATIONS_DIR,
    screenshot_dir: str = DEFAULT_SCREENSHOT_DIR,
    actions_dir: str = DEFAULT_ACTIONS_DIR,
    judgments_dir: str = DEFAULT_JUDGMENTS_DIR,
    task_proposals_dir: str = DEFAULT_TASK_PROPOSALS_DIR,
    max_actions: int = DEFAULT_MAX_ACTIONS,
    agent_response_key: str = DEFAULT_AGENT_RESPONSE_KEY,
    judge_response_key: str = DEFAULT_JUDGE_RESPONSE_KEY,
    skip_finished: bool = DEFAULT_SKIP_FINISHED,
    prune_observations: bool = DEFAULT_PRUNE_OBSERVATIONS,
    add_steps_to_agent: bool = DEFAULT_ADD_STEPS_TO_AGENT,
    add_criteria_to_agent: bool = DEFAULT_ADD_CRITERIA_TO_AGENT,
    add_steps_to_judge: bool = DEFAULT_ADD_STEPS_TO_JUDGE,
    add_criteria_to_judge: bool = DEFAULT_ADD_CRITERIA_TO_JUDGE,
    add_steps_to_task_proposer: bool = DEFAULT_ADD_STEPS_TO_TASK_PROPOSER,
    add_criteria_to_task_proposer: bool = DEFAULT_ADD_CRITERIA_TO_TASK_PROPOSER,
) -> None:
    """Run the InSTA pipeline for internet-scale data collection, and save
    the observations, actions, and judgments for each task.

    Arguments:

    dataset: List[Dict[str, str]]
        Override the default dataset, and run the pipeline on custom tasks,
        each entry must be a dictionary with keys "domain" and "task".

    agent: BrowserAgent | AgentConfig
        The LLM agent to use for the task.

    judge: BrowserJudge | JudgeConfig
        The LLM judge to evaluate the trajectory.

    browser: InstaEnv | BrowserConfig
        The web navigation environment running Playwright.

    rank: int
        Rank of the process.

    world_size: int
        Number of data collection processes.

    seed: int
        Seed for the dataset.

    observations_dir: str
        Directory to save observations.

    screenshot_dir: str
        Directory to save screenshots.

    actions_dir: str
        Directory to save actions.

    judgments_dir: str
        Directory to save judgments.

    max_actions: int
        Maximum number of actions per task.

    skip_finished: bool
        Whether to skip tasks that are already attempted.

    prune_observations: bool
        Whether to prune observations before saving.
    
    """

    for x in iter_trajectories(
        dataset = dataset, browser = browser,
        agent = agent, judge = judge,
        task_proposer = task_proposer,
        seed = seed, rank = rank, world_size = world_size,
        observations_dir = observations_dir,
        screenshot_dir = screenshot_dir,
        actions_dir = actions_dir,
        judgments_dir = judgments_dir,
        task_proposals_dir = task_proposals_dir,
        max_actions = max_actions,
        agent_response_key = agent_response_key,
        judge_response_key = judge_response_key,
        skip_finished = skip_finished,
        prune_observations = prune_observations,
        add_steps_to_agent = add_steps_to_agent,
        add_criteria_to_agent = add_criteria_to_agent,
        add_steps_to_judge = add_steps_to_judge,
        add_criteria_to_judge = add_criteria_to_judge,
        add_steps_to_task_proposer = add_steps_to_task_proposer,
        add_criteria_to_task_proposer = add_criteria_to_task_proposer,
    ):
        
        pass


DONE_SIGNAL: str = "DONE_SIGNAL"


def multiprocessing_wrapper(
    data_collection_fn: Callable,
    dataset: List[Dict[str, str]],
    agent_config: AgentConfig = DEFAULT_AGENT_CONFIG,
    judge_config: JudgeConfig = DEFAULT_JUDGE_CONFIG,
    task_proposer_config: TaskProposerConfig = DEFAULT_TASK_PROPOSER_CONFIG,
    seed: int = DEFAULT_SEED,
    observations_dir: str = DEFAULT_OBSERVATIONS_DIR,
    screenshot_dir: str = DEFAULT_SCREENSHOT_DIR,
    actions_dir: str = DEFAULT_ACTIONS_DIR,
    judgments_dir: str = DEFAULT_JUDGMENTS_DIR,
    task_proposals_dir: str = DEFAULT_TASK_PROPOSALS_DIR,
    max_actions: int = DEFAULT_MAX_ACTIONS,
    agent_response_key: str = DEFAULT_AGENT_RESPONSE_KEY,
    judge_response_key: str = DEFAULT_JUDGE_RESPONSE_KEY,
    skip_finished: bool = DEFAULT_SKIP_FINISHED,
    prune_observations: bool = DEFAULT_PRUNE_OBSERVATIONS,
    add_steps_to_agent: bool = DEFAULT_ADD_STEPS_TO_AGENT,
    add_criteria_to_agent: bool = DEFAULT_ADD_CRITERIA_TO_AGENT,
    add_steps_to_judge: bool = DEFAULT_ADD_STEPS_TO_JUDGE,
    add_criteria_to_judge: bool = DEFAULT_ADD_CRITERIA_TO_JUDGE,
    add_steps_to_task_proposer: bool = DEFAULT_ADD_STEPS_TO_TASK_PROPOSER,
    add_criteria_to_task_proposer: bool = DEFAULT_ADD_CRITERIA_TO_TASK_PROPOSER,
):

    def worker_fn(
        output_queue: Queue,
        browser_config: BrowserConfig,
        rank: int,
        world_size: int,
    ):
        
        os.environ['VLLM_WORKER_MULTIPROC_METHOD'] = 'spawn'

        if torch.cuda.device_count() > 0:

            os.environ["CUDA_VISIBLE_DEVICES"] = "{}".format(
                rank % torch.cuda.device_count()
            )

        outputs = data_collection_fn(
            dataset = dataset, browser = browser_config,
            agent = agent_config,
            judge = judge_config,
            task_proposer = task_proposer_config,
            seed = seed, rank = rank, world_size = world_size,
            observations_dir = observations_dir,
            screenshot_dir = screenshot_dir,
            actions_dir = actions_dir,
            judgments_dir = judgments_dir,
            task_proposals_dir = task_proposals_dir,
            max_actions = max_actions,
            agent_response_key = agent_response_key,
            judge_response_key = judge_response_key,
            skip_finished = skip_finished,
            prune_observations = prune_observations,
            add_steps_to_agent = add_steps_to_agent,
            add_criteria_to_agent = add_criteria_to_agent,
            add_steps_to_judge = add_steps_to_judge,
            add_criteria_to_judge = add_criteria_to_judge,
            add_steps_to_task_proposer = add_steps_to_task_proposer,
            add_criteria_to_task_proposer = add_criteria_to_task_proposer,
        )
        
        if outputs is not None:

            for output in outputs:

                output_queue.put(output)

        output_queue.put(DONE_SIGNAL)

    return worker_fn


NULL_QUEUE = None


def launch_data_collection(
    dataset: List[Dict[str, str]],
    browser_config: BrowserConfig = DEFAULT_BROWSER_CONFIG,
    agent_config: AgentConfig = DEFAULT_AGENT_CONFIG,
    judge_config: JudgeConfig = DEFAULT_JUDGE_CONFIG,
    task_proposer_config: TaskProposerConfig = DEFAULT_TASK_PROPOSER_CONFIG,
    seed: int = DEFAULT_SEED,
    rank: int = DEFAULT_RANK,
    world_size: int = DEFAULT_WORLD_SIZE,
    observations_dir: str = DEFAULT_OBSERVATIONS_DIR,
    screenshot_dir: str = DEFAULT_SCREENSHOT_DIR,
    actions_dir: str = DEFAULT_ACTIONS_DIR,
    judgments_dir: str = DEFAULT_JUDGMENTS_DIR,
    task_proposals_dir: str = DEFAULT_TASK_PROPOSALS_DIR,
    max_actions: int = DEFAULT_MAX_ACTIONS,
    agent_response_key: str = DEFAULT_AGENT_RESPONSE_KEY,
    judge_response_key: str = DEFAULT_JUDGE_RESPONSE_KEY,
    skip_finished: bool = DEFAULT_SKIP_FINISHED,
    prune_observations: bool = DEFAULT_PRUNE_OBSERVATIONS,
    add_steps_to_agent: bool = DEFAULT_ADD_STEPS_TO_AGENT,
    add_criteria_to_agent: bool = DEFAULT_ADD_CRITERIA_TO_AGENT,
    add_steps_to_judge: bool = DEFAULT_ADD_STEPS_TO_JUDGE,
    add_criteria_to_judge: bool = DEFAULT_ADD_CRITERIA_TO_JUDGE,
    add_steps_to_task_proposer: bool = DEFAULT_ADD_STEPS_TO_TASK_PROPOSER,
    add_criteria_to_task_proposer: bool = DEFAULT_ADD_CRITERIA_TO_TASK_PROPOSER,
    return_trajectories: bool = DEFAULT_RETURN_TRAJECTORIES,
    num_agents: int = DEFAULT_NUM_AGENTS,
    playwright_workers: int = DEFAULT_PLAYWRIGHT_WORKERS,
) -> List[InstaPipelineOutput] | None:
    """Run parallel agents to complete web navigation tasks,
    such as for performing Deep Research across the whole internet.

    Arguments:

    dataset: List[Dict[str, str]]
        Override the default dataset, and run the pipeline on custom tasks,
        each entry must be a dictionary with keys "domain" and "task".

    browser: InstaEnv
        The web navigation environment running Playwright.

    agent: BrowserAgent
        The LLM agent to use for the task.

    judge: BrowserJudge
        The LLM judge to evaluate the trajectory.

    observations_dir: str
        Directory to save observations.

    screenshot_dir: str
        Directory to save screenshots.

    actions_dir: str
        Directory to save actions.

    judgments_dir: str
        Directory to save judgments.

    max_actions: int
        Maximum number of actions per task.

    skip_finished: bool
        Whether to skip tasks that are already attempted.

    prune_observations: bool
        Whether to prune observations before saving.

    seed: int
        Seed for the dataset.

    return_trajectories: bool
        Whether to return trajectories or just save them.
        
    num_agents: int
        Number of parallel agents to run.

    playwright_workers: int
        Number of Playwright workers running.

    rank: int
        Rank of the machine.

    world_size: int
        Number of data collection machines.

    Returns:

    List[InstaPipelineOutput] | None
        List with observations, actions, and judgments for each task, 
        which are saved to disk for later processing.
    
    """

    worker_fn = (
        list_trajectories
        if return_trajectories else
        save_trajectories
    )

    worker_fn = multiprocessing_wrapper(
        worker_fn,
        dataset = dataset,
        agent_config = agent_config,
        judge_config = judge_config,
        task_proposer_config = task_proposer_config,
        seed = seed,
        observations_dir = observations_dir,
        screenshot_dir = screenshot_dir,
        actions_dir = actions_dir,
        judgments_dir = judgments_dir,
        task_proposals_dir = task_proposals_dir,
        max_actions = max_actions,
        agent_response_key = agent_response_key,
        judge_response_key = judge_response_key,
        skip_finished = skip_finished,
        prune_observations = prune_observations,
        add_steps_to_agent = add_steps_to_agent,
        add_criteria_to_agent = add_criteria_to_agent,
        add_steps_to_judge = add_steps_to_judge,
        add_criteria_to_judge = add_criteria_to_judge,
        add_steps_to_task_proposer = add_steps_to_task_proposer,
        add_criteria_to_task_proposer = add_criteria_to_task_proposer,
    )

    browser_config_dict = asdict(browser_config)

    total_agent_size = (
        world_size * num_agents
    )

    worker_processes = []
    worker_queues = []

    for agent_rank in range(
            rank * num_agents,
            (rank + 1) * num_agents):

        browser_config = get_browser_config(
            playwright_url = browser_config_dict["playwright_url"],
            playwright_port = (
                browser_config_dict["playwright_port"] +
                agent_rank % playwright_workers
            )
        )

        output_queue = Queue()

        worker_args = (
            output_queue,
            browser_config,
            agent_rank,
            total_agent_size
        )

        worker_process = Process(
            target = worker_fn,
            args = worker_args
        )

        worker_process.start()

        worker_processes.append(
            worker_process
        )

        worker_queues.append(
            output_queue
        )

    pipeline_outputs = []
        
    for idx, queue in (
        x for repeat in count() 
        for x in enumerate(worker_queues)
    ):

        time.sleep(0.01)

        all_queues_finished = all(
            queue_i is NULL_QUEUE
            for queue_i in worker_queues
        )

        if all_queues_finished:
    
            break

        queue_is_empty = (
            queue is NULL_QUEUE
            or queue.empty()
        )

        if queue_is_empty:

            continue

        output = queue.get()

        worker_finished = (
            output == DONE_SIGNAL
        )

        if worker_finished:

            worker_queues[idx] = (
                NULL_QUEUE
            )

        elif isinstance(
            output, InstaPipelineOutput
        ):

            pipeline_outputs.append(
                output
            )

    for worker_process in worker_processes:

        worker_process.join()

    if return_trajectories:

        return pipeline_outputs


class InstaPipeline(Callable):
    """Initialize the InSTA pipeline for internet-scale data collection,
    creates a browser, LLM agent, and LLM judge, then runs the agent
    to attempt web navigation tasks from the InSTA-150k dataset.

    Attributes:

    agent: BrowserAgent
        The LLM agent to use for the task.

    judge: BrowserJudge
        The LLM judge to evaluate the trajectory.

    browser: InstaEnv
        The web navigation environment running Playwright.

    """

    browser: InstaEnv = None
    agent: BrowserAgent = None
    judge: BrowserJudge = None
    task_proposer: BrowserTaskProposer = None

    def __init__(self, browser_config: BrowserConfig = DEFAULT_BROWSER_CONFIG,
                 agent_config: AgentConfig = DEFAULT_AGENT_CONFIG,
                 judge_config: JudgeConfig = DEFAULT_JUDGE_CONFIG,
                 task_proposer_config: TaskProposerConfig = DEFAULT_TASK_PROPOSER_CONFIG,
                 seed: int = DEFAULT_SEED,
                 rank: int = DEFAULT_RANK,
                 world_size: int = DEFAULT_WORLD_SIZE,
                 observations_dir: str = DEFAULT_OBSERVATIONS_DIR,
                 screenshot_dir: str = DEFAULT_SCREENSHOT_DIR,
                 actions_dir: str = DEFAULT_ACTIONS_DIR,
                 judgments_dir: str = DEFAULT_JUDGMENTS_DIR,
                 task_proposals_dir: str = DEFAULT_TASK_PROPOSALS_DIR,
                 max_actions: int = DEFAULT_MAX_ACTIONS,
                 agent_response_key: str = DEFAULT_AGENT_RESPONSE_KEY,
                 judge_response_key: str = DEFAULT_JUDGE_RESPONSE_KEY,
                 skip_finished: bool = DEFAULT_SKIP_FINISHED,
                 prune_observations: bool = DEFAULT_PRUNE_OBSERVATIONS,
                 add_steps_to_agent: bool = DEFAULT_ADD_STEPS_TO_AGENT,
                 add_criteria_to_agent: bool = DEFAULT_ADD_CRITERIA_TO_AGENT,
                 add_steps_to_judge: bool = DEFAULT_ADD_STEPS_TO_JUDGE,
                 add_criteria_to_judge: bool = DEFAULT_ADD_CRITERIA_TO_JUDGE,
                 add_steps_to_task_proposer: bool = DEFAULT_ADD_STEPS_TO_TASK_PROPOSER,
                 add_criteria_to_task_proposer: bool = DEFAULT_ADD_CRITERIA_TO_TASK_PROPOSER):
        """Initialize the InSTA pipeline for internet-scale data collection,
        creates a browser, LLM agent, and LLM judge, then runs the agent
        to attempt web navigation tasks from the InSTA-150k dataset.

        Arguments:

        agent_config: AgentConfig
            Configuration for the LLM agent.

        judge_config: JudgeConfig
            Configuration for the LLM judge.

        browser_config: BrowserConfig
            Configuration for the Playwright environment.

        rank: int
            Rank of the process.

        world_size: int
            Number of data collection processes.

        seed: int
            Seed for the dataset.

        observations_dir: str
            Directory to save observations.

        screenshot_dir: str
            Directory to save screenshots.

        actions_dir: str
            Directory to save actions.

        judgments_dir: str
            Directory to save judgments.

        max_actions: int
            Maximum number of actions per task.

        skip_finished: bool
            Whether to skip tasks that are already attempted.

        prune_observations: bool
            Whether to prune observations before saving.
        
        """

        self.browser_config = browser_config
        self.agent_config = agent_config
        self.judge_config = judge_config
        self.task_proposer_config = task_proposer_config

        self.seed = seed
        self.rank = rank
        self.world_size = world_size

        self.observations_dir = observations_dir
        self.screenshot_dir = screenshot_dir
        self.actions_dir = actions_dir
        self.judgments_dir = judgments_dir
        self.task_proposals_dir = task_proposals_dir

        self.max_actions = max_actions
        self.agent_response_key = agent_response_key
        self.judge_response_key = judge_response_key

        self.skip_finished = skip_finished
        self.prune_observations = prune_observations

        self.add_steps_to_agent = add_steps_to_agent
        self.add_criteria_to_agent = add_criteria_to_agent

        self.add_steps_to_judge = add_steps_to_judge
        self.add_criteria_to_judge = add_criteria_to_judge

        self.add_steps_to_task_proposer = add_steps_to_task_proposer
        self.add_criteria_to_task_proposer = add_criteria_to_task_proposer

    def generate_trajectory(
        self, url: str, instruction: str
    ) -> Tuple[List[Dict], List[Dict], Dict]:
        """Attempt a web navigation task using the LLM agent, and return the
        observations and actions along the trajectory for later processing.

        Arguments:

        url: str
            Starting URL for the agent.

        instruction: str
            Specific instruction for the agent.

        Returns:

        Tuple[List[Dict], List[Dict], Dict]
            Tuple containing observations, actions, and judgment for the trajectory
            generated by running the agent with an instruction.
        
        """

        if self.browser is None:

            self.browser = InstaEnv(
                config = self.browser_config
            )

        if self.agent is None:

            self.agent = BrowserAgent(
                config = self.agent_config
            )

        if self.judge is None:

            self.judge = BrowserJudge(
                config = self.judge_config
            )

        if self.task_proposer is None:

            self.task_proposer = BrowserTaskProposer(
                config = self.task_proposer_config
            )
        
        trajectory = safe_call(
            generate_trajectory, browser = self.browser,
            agent = self.agent, judge = self.judge,
            task_proposer = self.task_proposer,
            url = url, instruction = instruction,
            max_actions = self.max_actions,
            agent_response_key = self.agent_response_key,
            judge_response_key = self.judge_response_key,
            catch_errors = True,
            log_errors = True,
            max_errors = 1,
        )

        observations, actions, judgment, task_proposal = [], [], {}, {}

        if trajectory is not BrowserStatus.ERROR:

            observations, actions, judgment, task_proposal = trajectory
        
        return observations, actions, judgment, task_proposal
        
    def __call__(self, url: str, instruction: str) -> Tuple[List[Dict], List[Dict], Dict, Dict]:
        """Attempt a web navigation task using the LLM agent, and return the
        observations and actions along the trajectory for later processing.

        Arguments:

        url: str
            Starting URL for the agent.

        instruction: str
            Specific instruction for the agent.

        Returns:

        Tuple[List[Dict], List[Dict], Dict]
            Tuple containing observations, actions, and judgment for the trajectory
            generated by running the agent with an instruction.
        
        """
        
        return self.generate_trajectory(
            url = url, instruction = instruction
        )

    def iter_trajectories(
        self, dataset: List[Dict[str, str]]
    ) -> Generator[InstaPipelineOutput, None, None]:
        """Run the InSTA pipeline for internet-scale data collection, and yield
        the observations, actions, and judgments for each task.

        Arguments:

        dataset: List[Dict[str, str]]
            Override the default dataset, and run the pipeline on custom tasks,
            each entry must be a dictionary with keys "domain" and "task".

        Returns:

        Generator[InstaPipelineOutput, None, None]
            Generator for the observations, actions, and judgments for each task, 
            which are saved to disk for later processing.
        
        """

        if self.browser is None:

            self.browser = InstaEnv(
                config = self.browser_config
            )

        if self.agent is None:

            self.agent = BrowserAgent(
                config = self.agent_config
            )

        if self.judge is None:

            self.judge = BrowserJudge(
                config = self.judge_config
            )

        if self.task_proposer is None:

            self.task_proposer = BrowserTaskProposer(
                config = self.task_proposer_config
            )

        yield from iter_trajectories(
            dataset = dataset, browser = self.browser,
            agent = self.agent, judge = self.judge, 
            task_proposer = self.task_proposer,
            seed = self.seed, rank = self.rank, world_size = self.world_size,
            observations_dir = self.observations_dir,
            screenshot_dir = self.screenshot_dir,
            actions_dir = self.actions_dir,
            judgments_dir = self.judgments_dir,
            task_proposals_dir = self.task_proposals_dir,
            max_actions = self.max_actions,
            agent_response_key = self.agent_response_key,
            judge_response_key = self.judge_response_key,
            skip_finished = self.skip_finished,
            prune_observations = self.prune_observations,
            add_steps_to_agent = self.add_steps_to_agent,
            add_criteria_to_agent = self.add_criteria_to_agent,
            add_steps_to_judge = self.add_steps_to_judge,
            add_criteria_to_judge = self.add_criteria_to_judge,
            add_steps_to_task_proposer = self.add_steps_to_task_proposer,
            add_criteria_to_task_proposer = self.add_criteria_to_task_proposer,
        )

    def list_trajectories(
        self, dataset: List[Dict[str, str]]
    ) -> List[InstaPipelineOutput]:
        """Run the InSTA pipeline for internet-scale data collection, and list
        the observations, actions, and judgments for each task.

        Arguments:

        dataset: List[Dict[str, str]]
            Override the default dataset, and run the pipeline on custom tasks,
            each entry must be a dictionary with keys "domain" and "task".

        Returns:

        List[InstaPipelineOutput]
            List with observations, actions, and judgments for each task, 
            which are saved to disk for later processing.
        
        """

        if self.browser is None:

            self.browser = InstaEnv(
                config = self.browser_config
            )

        if self.agent is None:

            self.agent = BrowserAgent(
                config = self.agent_config
            )

        if self.judge is None:

            self.judge = BrowserJudge(
                config = self.judge_config
            )

        if self.task_proposer is None:

            self.task_proposer = BrowserTaskProposer(
                config = self.task_proposer_config
            )

        return list_trajectories(
            dataset = dataset, browser = self.browser,
            agent = self.agent, judge = self.judge, 
            task_proposer = self.task_proposer,
            seed = self.seed, rank = self.rank, world_size = self.world_size,
            observations_dir = self.observations_dir,
            screenshot_dir = self.screenshot_dir,
            actions_dir = self.actions_dir,
            judgments_dir = self.judgments_dir,
            task_proposals_dir = self.task_proposals_dir,
            max_actions = self.max_actions,
            agent_response_key = self.agent_response_key,
            judge_response_key = self.judge_response_key,
            skip_finished = self.skip_finished,
            prune_observations = self.prune_observations,
            add_steps_to_agent = self.add_steps_to_agent,
            add_criteria_to_agent = self.add_criteria_to_agent,
            add_steps_to_judge = self.add_steps_to_judge,
            add_criteria_to_judge = self.add_criteria_to_judge,
            add_steps_to_task_proposer = self.add_steps_to_task_proposer,
            add_criteria_to_task_proposer = self.add_criteria_to_task_proposer,
        )

    def save_trajectories(self, dataset: List[Dict[str, str]]) -> None:
        """Run the InSTA pipeline for internet-scale data collection, and save
        the observations, actions, and judgments for each task.

        Arguments:

        dataset: List[Dict[str, str]]
            Override the default dataset, and run the pipeline on custom tasks,
            each entry must be a dictionary with keys "domain" and "task".
        
        """

        if self.browser is None:

            self.browser = InstaEnv(
                config = self.browser_config
            )

        if self.agent is None:

            self.agent = BrowserAgent(
                config = self.agent_config
            )

        if self.judge is None:

            self.judge = BrowserJudge(
                config = self.judge_config
            )

        if self.task_proposer is None:

            self.task_proposer = BrowserTaskProposer(
                config = self.task_proposer_config
            )

        save_trajectories(
            dataset = dataset, browser = self.browser,
            agent = self.agent, judge = self.judge, 
            task_proposer = self.task_proposer,
            seed = self.seed, rank = self.rank, world_size = self.world_size,
            observations_dir = self.observations_dir,
            screenshot_dir = self.screenshot_dir,
            actions_dir = self.actions_dir,
            judgments_dir = self.judgments_dir,
            task_proposals_dir = self.task_proposals_dir,
            max_actions = self.max_actions,
            agent_response_key = self.agent_response_key,
            judge_response_key = self.judge_response_key,
            skip_finished = self.skip_finished,
            prune_observations = self.prune_observations,
            add_steps_to_agent = self.add_steps_to_agent,
            add_criteria_to_agent = self.add_criteria_to_agent,
            add_steps_to_judge = self.add_steps_to_judge,
            add_criteria_to_judge = self.add_criteria_to_judge,
            add_steps_to_task_proposer = self.add_steps_to_task_proposer,
            add_criteria_to_task_proposer = self.add_criteria_to_task_proposer,
        )

    def launch(
        self, dataset: List[Dict[str, str]],
        return_trajectories: bool = DEFAULT_RETURN_TRAJECTORIES,
        num_agents: int = DEFAULT_NUM_AGENTS,
        playwright_workers: int = DEFAULT_PLAYWRIGHT_WORKERS,
    ) -> List[InstaPipelineOutput] | None:
        """Run parallel agents to complete web navigation tasks,
        such as for performing Deep Research across the whole internet.

        Arguments:

        dataset: List[Dict[str, str]]
            Override the default dataset, and run the pipeline on custom tasks,
            each entry must be a dictionary with keys "domain" and "task".

        return_trajectories: bool
            Whether to return trajectories or just save them.

        num_agents: int
            Number of parallel agents to run.

        playwright_workers: int
            Number of Playwright workers running.

        Returns:

        List[InstaPipelineOutput] | None
            List with observations, actions, and judgments for each task, 
            which are saved to disk for later processing.
        
        """

        return launch_data_collection(
            dataset = dataset,
            browser_config = self.browser_config,
            agent_config = self.agent_config,
            judge_config = self.judge_config,
            task_proposer_config = self.task_proposer_config,
            seed = self.seed,
            rank = self.rank,
            world_size = self.world_size,
            observations_dir = self.observations_dir,
            screenshot_dir = self.screenshot_dir,
            actions_dir = self.actions_dir,
            judgments_dir = self.judgments_dir,
            task_proposals_dir = self.task_proposals_dir,
            max_actions = self.max_actions,
            agent_response_key = self.agent_response_key,
            judge_response_key = self.judge_response_key,
            skip_finished = self.skip_finished,
            prune_observations = self.prune_observations,
            add_steps_to_agent = self.add_steps_to_agent,
            add_criteria_to_agent = self.add_criteria_to_agent,
            add_steps_to_judge = self.add_steps_to_judge,
            add_criteria_to_judge = self.add_criteria_to_judge,
            add_steps_to_task_proposer = self.add_steps_to_task_proposer,
            add_criteria_to_task_proposer = self.add_criteria_to_task_proposer,
            return_trajectories = return_trajectories,
            num_agents = num_agents,
            playwright_workers = playwright_workers,
        )
