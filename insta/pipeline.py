from typing import Callable, Tuple, List, Dict, Generator
from collections import namedtuple

from insta.configs import (
    DEFAULT_AGENT_CONFIG,
    DEFAULT_JUDGE_CONFIG,
    DEFAULT_BROWSER_CONFIG,
    AgentConfig,
    JudgeConfig,
    BrowserConfig,
)

from insta.gym_env import (
    InstaEnv,
    BrowserAction,
    InstaEnvResetOutput,
    InstaEnvStepOutput
)

from insta.agent import (
    BrowserAgent,
    NULL_ACTION
)

from insta.judge import (
    BrowserJudge,
    NULL_JUDGMENT
)

import random
import tqdm
import json
import os


DEFAULT_OBSERVATIONS_DIR = "data/observations"
DEFAULT_SCREENSHOT_DIR = "data/screenshots"
DEFAULT_ACTIONS_DIR = "data/actions"
DEFAULT_JUDGMENTS_DIR = "data/judgments"


DEFAULT_MAX_ACTIONS = 30
DEFAULT_SKIP_FINISHED = False
DEFAULT_PRUNE_OBSERVATIONS = False


DEFAULT_SEED = 123
DEFAULT_RANK = 0
DEFAULT_WORLD_SIZE = 1


METADATA_KEYS = [
    'backend_node_id',
    'bounding_client_rect',
    'computed_style',
    'scroll_left',
    'scroll_top',
    'editable_value',
    'is_visible',
    'is_frontmost'
]


VALUES_KEYS = [
    "task_is_feasible",
    "success",
    "on_right_track"
]


STYLE_KEYS_TO_KEEP = [
    'display'
]


InstaPipelineOutput = namedtuple(
    "InstaPipelineOutput",
    ["observations", "actions", "judgment"]
)


def generate_trajectory(
    env: InstaEnv, agent: BrowserAgent, judge: BrowserJudge,
    url: str, instruction: str,
    max_actions: int = DEFAULT_MAX_ACTIONS,
) -> Tuple[List[Dict], List[Dict], Dict]:
    """Attempt a web navigation task using the LLM agent, and return the
    observations and actions along the trajectory for later processing.

    Arguments:

    env: InstaEnv
        The web navigation environment running Playwright.

    agent: BrowserAgent
        The LLM agent to use for the task.

    judge: BrowserJudge
        The LLM judge to evaluate the trajectory.

    url: str
        Starting URL for the agent.

    instruction: str
        Specific instruction for the agent.

    max_actions: int
        Maximum number of actions per task.

    Returns:

    Tuple[List[Dict], List[Dict], Dict]
        Tuple containing observations, actions, and judgment for the trajectory
        generated by running the agent with an instruction.
    
    """

    observations = []
    actions = []

    action = NULL_ACTION

    for t in range(max_actions):

        outputs = None

        if action is not NULL_ACTION:

            agent.push_action(
                response = action.response
            )

            outputs = env.step(
                action = action
            )

        elif t == 0:

            agent.reset()

            outputs = env.reset(
                url = url
            )

        is_finished = outputs is None or (
            isinstance(outputs, InstaEnvStepOutput)
            and outputs.done
        )

        if is_finished:
            
            break

        obs = outputs.observation

        for key, value in (obs.metadata or {}).items():

            obs.metadata[key] = {
                key: value.get(key)
                for key in METADATA_KEYS
            } 

        observations.append({
            "current_url": obs.current_url,
            "processed_text": obs.processed_text,
            "raw_html": obs.raw_html,
            "screenshot": obs.screenshot,
            "metadata": obs.metadata
        })

        agent.pop_observation()
        
        action = agent(
            observation = obs.processed_text,
            instruction = instruction
        )

        function_calls = [
            {"dotpath": x.dotpath, "args": x.args}
            for x in action.function_calls
        ]

        actions.append({
            "function_calls": function_calls,
            "response": action.response,
            "matched_response": action.matched_response
        })

    judgment = judge(
        observations = [
            x["processed_text"]
            for x in observations
        ],
        actions = [
            x["response"]
            for x in actions
        ],
        instruction = instruction
    )

    judgment_values = {
        key: judgment.values.get(key)
        for key in VALUES_KEYS
    }

    judgment = {
        **judgment_values,
        "response": judgment.response,
        "matched_response": judgment.matched_response,
    }

    return observations, actions, judgment


def iter_trajectories(
    dataset: List[Dict[str, str]],
    agent: BrowserAgent, judge: BrowserJudge, env: InstaEnv,
    observations_dir: str = DEFAULT_OBSERVATIONS_DIR,
    screenshot_dir: str = DEFAULT_SCREENSHOT_DIR,
    actions_dir: str = DEFAULT_ACTIONS_DIR,
    judgments_dir: str = DEFAULT_JUDGMENTS_DIR,
    max_actions: int = DEFAULT_MAX_ACTIONS,
    skip_finished: bool = DEFAULT_SKIP_FINISHED,
    prune_observations: bool = DEFAULT_PRUNE_OBSERVATIONS,
    seed: int = DEFAULT_SEED,
    rank: int = DEFAULT_RANK,
    world_size: int = DEFAULT_WORLD_SIZE
) -> Generator[InstaPipelineOutput, None, None]:
    """Run the InSTA pipeline for internet-scale data collection, and yield
    the observations, actions, and judgments for each task.

    Arguments:

    dataset: List[Dict[str, str]]
        Override the default dataset, and run the pipeline on custom tasks,
        each entry must be a dictionary with keys "domain" and "task".

    env: InstaEnv
        The web navigation environment running Playwright.

    agent: BrowserAgent
        The LLM agent to use for the task.

    judge: BrowserJudge
        The LLM judge to evaluate the trajectory.

    observations_dir: str
        Directory to save observations.

    screenshot_dir: str
        Directory to save screenshots.

    actions_dir: str
        Directory to save actions.

    judgments_dir: str
        Directory to save judgments.

    max_actions: int
        Maximum number of actions per task.

    skip_finished: bool
        Whether to skip tasks that are already attempted.

    prune_observations: bool
        Whether to prune observations before saving.

    seed: int
        Seed for the dataset.

    rank: int
        Rank of the process.

    world_size: int
        Number of data collection processes.

    Returns:

    Generator[InstaPipelineOutput, None, None]
        Generator for the observations, actions, and judgments for each task, 
        which are saved to disk for later processing.
    
    """

    os.makedirs(
        observations_dir, 
        exist_ok = True
    )

    os.makedirs(
        screenshot_dir, 
        exist_ok = True
    )

    os.makedirs(
        actions_dir, 
        exist_ok = True
    )

    os.makedirs(
        judgments_dir, 
        exist_ok = True
    )

    dataset_ids = list(range(len(dataset)))

    random.seed(seed)
    random.shuffle(dataset_ids)

    dataset_ids = dataset_ids[
        rank::world_size
    ]

    progress_bar = tqdm.tqdm(
        dataset_ids, desc = "Processing",
        dynamic_ncols = True
    )

    for example_id in progress_bar:

        example_dict = dataset[example_id]
        domain = example_dict["domain"]

        url = "http://{}".format(domain)
        instruction = example_dict["task"]

        progress_bar.set_description(
            "Processing: {}".format(
                domain
            )
        )

        observations_path = os.path.join(
            observations_dir,
            "{}.json".format(domain)
        )

        actions_path = os.path.join(
            actions_dir,
            "{}.json".format(domain)
        )

        judgments_path = os.path.join(
            judgments_dir,
            "{}.json".format(domain)
        )

        screenshot_dir = os.path.join(
            screenshot_dir,
            "{}".format(domain)
        )

        skip_this_task = (
            skip_finished and
            os.path.exists(judgments_path)
        )

        if skip_this_task:

            continue
        
        observations, actions, judgment = generate_trajectory(
            env = env, agent = agent, judge = judge,
            url = url, instruction = instruction,
            max_actions = max_actions
        )

        os.makedirs(
            screenshot_dir,
            exist_ok = True
        )

        for step_idx, observation in enumerate(observations):

            screenshot = observation.pop(
                "screenshot"
            )

            if screenshot is not None:

                screenshot_path = os.path.join(
                    screenshot_dir,
                    "screenshot_{:02d}.jpg"
                    .format(step_idx)
                )

                screenshot.convert("RGB").save(
                    screenshot_path
                )

                observation["screenshot_path"] = (
                    screenshot_path
                )

            if prune_observations:
                
                observations[step_idx] = (
                    prune_observation(
                        observation
                    )
                )
                
        with open(observations_path, "w") as file:
            
            json.dump(
                observations, 
                file,
                indent = 4
            )

        with open(actions_path, "w") as file:
            
            json.dump(
                actions, 
                file,
                indent = 4
            )

        with open(judgments_path, "w") as file:
            
            json.dump(
                judgment, 
                file,
                indent = 4
            )

        yield InstaPipelineOutput(
            observations = observations,
            actions = actions,
            judgment = judgment
        )


def prune_observation(observation: dict) -> dict:
    """Reduce the size of the computed styles in the observations file
    by removing keys that are not needed.

    Arguments:

    observations_file: str
        The path to the observations file to prune.

    """

    if observation["metadata"] is None:
        
        return observation

    for backend_node_id in observation["metadata"].keys():

        computed_style = observation["metadata"][
            backend_node_id
        ]["computed_style"]

        computed_style_keys = list(computed_style.keys())

        for key in computed_style_keys:

            if key not in STYLE_KEYS_TO_KEEP:

                del computed_style[key]

    return observation


class InstaPipeline(Callable):
    """Initialize the InSTA pipeline for internet-scale data collection,
    creates a browser, LLM agent, and LLM judge, then runs the agent
    to attempt web navigation tasks from the InSTA-150k dataset.

    """

    agent: BrowserAgent = None
    judge: BrowserJudge = None
    env: InstaEnv = None

    def __init__(self, agent_config: AgentConfig = DEFAULT_AGENT_CONFIG,
                 judge_config: JudgeConfig = DEFAULT_JUDGE_CONFIG,
                 browser_config: BrowserConfig = DEFAULT_BROWSER_CONFIG,
                 observations_dir: str = DEFAULT_OBSERVATIONS_DIR,
                 screenshot_dir: str = DEFAULT_SCREENSHOT_DIR,
                 actions_dir: str = DEFAULT_ACTIONS_DIR,
                 judgments_dir: str = DEFAULT_JUDGMENTS_DIR,
                 max_actions: int = DEFAULT_MAX_ACTIONS,
                 skip_finished: bool = DEFAULT_SKIP_FINISHED,
                 prune_observations: bool = DEFAULT_PRUNE_OBSERVATIONS,
                 seed: int = DEFAULT_SEED,
                 rank: int = DEFAULT_RANK,
                 world_size: int = DEFAULT_WORLD_SIZE):
        """Initialize the InSTA pipeline for internet-scale data collection,
        creates a browser, LLM agent, and LLM judge, then runs the agent
        to attempt web navigation tasks from the InSTA-150k dataset.

        Arguments:

        agent_config: AgentConfig
            Configuration for the LLM agent.

        judge_config: JudgeConfig
            Configuration for the LLM judge.

        browser_config: BrowserConfig
            Configuration for the Playwright environment.

        observations_dir: str
            Directory to save observations.

        screenshot_dir: str
            Directory to save screenshots.

        actions_dir: str
            Directory to save actions.

        judgments_dir: str
            Directory to save judgments.

        max_actions: int
            Maximum number of actions per task.

        skip_finished: bool
            Whether to skip tasks that are already attempted.

        prune_observations: bool
            Whether to prune observations before saving.

        seed: int
            Seed for the dataset.

        rank: int
            Rank of the process.

        world_size: int
            Number of data collection processes.
        
        """

        self.agent_config = agent_config
        self.judge_config = judge_config
        self.browser_config = browser_config

        self.observations_dir = observations_dir
        self.screenshot_dir = screenshot_dir
        self.actions_dir = actions_dir
        self.judgments_dir = judgments_dir

        self.max_actions = max_actions
        self.skip_finished = skip_finished
        self.prune_observations = prune_observations

        self.seed = seed
        self.rank = rank
        self.world_size = world_size

        self.agent = BrowserAgent(
            config = self.agent_config
        )

        self.judge = BrowserJudge(
            config = self.judge_config
        )

        self.env = InstaEnv(
            config = self.browser_config
        )

    def generate_trajectory(
        self, url: str, instruction: str
    ) -> Tuple[List[Dict], List[Dict], Dict]:
        """Attempt a web navigation task using the LLM agent, and return the
        observations and actions along the trajectory for later processing.

        Arguments:

        url: str
            Starting URL for the agent.

        instruction: str
            Specific instruction for the agent.

        Returns:

        Tuple[List[Dict], List[Dict], Dict]
            Tuple containing observations, actions, and judgment for the trajectory
            generated by running the agent with an instruction.
        
        """
    
        observations, actions, judgment = generate_trajectory(
            env = self.env, agent = self.agent, judge = self.judge,
            url = url, instruction = instruction,
            max_actions = self.max_actions
        )

        return observations, actions, judgment
    
    def __call__(self, url: str, instruction: str) -> Tuple[List[Dict], List[Dict]]:
        """Attempt a web navigation task using the LLM agent, and return the
        observations and actions along the trajectory for later processing.

        Arguments:

        url: str
            Starting URL for the agent.

        instruction: str
            Specific instruction for the agent.

        Returns:

        Tuple[List[Dict], List[Dict], Dict]
            Tuple containing observations, actions, and judgment for the trajectory
            generated by running the agent with an instruction.
        
        """
        
        return self.generate_trajectory(
            url = url, instruction = instruction
        )

    def iter_trajectories(
        self, dataset: List[Dict[str, str]] = None
    ) -> Generator[InstaPipelineOutput, None, None]:
        """Run the InSTA pipeline for internet-scale data collection, and yield
        the observations, actions, and judgments for each task.

        Arguments:

        dataset: List[Dict[str, str]]
            Override the default dataset, and run the pipeline on custom tasks,
            each entry must be a dictionary with keys "domain" and "task".

        Returns:

        Generator[InstaPipelineOutput, None, None]
            Generator for the observations, actions, and judgments for each task, 
            which are saved to disk for later processing.
        
        """

        yield from iter_trajectories(
            dataset = dataset, env = self.env,
            agent = self.agent, judge = self.judge, 
            observations_dir = self.observations_dir,
            screenshot_dir = self.screenshot_dir,
            actions_dir = self.actions_dir,
            judgments_dir = self.judgments_dir,
            max_actions = self.max_actions,
            skip_finished = self.skip_finished,
            prune_observations = self.prune_observations,
            seed = self.seed,
            rank = self.rank,
            world_size = self.world_size
        )
 
    def run(self, dataset: List[Dict[str, str]] = None) -> None:
        """Run the InSTA pipeline for internet-scale data collection, and yield
        the observations, actions, and judgments for each task.

        Arguments:

        dataset: List[Dict[str, str]]
            Override the default dataset, and run the pipeline on custom tasks,
            each entry must be a dictionary with keys "domain" and "task".

        """

        for x in self.iter_trajectories(
            dataset = dataset
        ):
            
            pass
