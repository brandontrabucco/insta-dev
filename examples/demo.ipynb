{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7dff3de",
   "metadata": {},
   "source": [
    "# InSTA: Towards Internet-Scale Training For Agents\n",
    "\n",
    "![Pipeline Overview](https://data-for-agents.github.io/static/images/pipeline_overview.png)\n",
    "\n",
    "**Brandon Trabucco (1) Gunnar Sigurdsson (2) Robinson Piramuthu (2) Ruslan Salakhutdinov (1)**\n",
    "\n",
    "**(1) Carnegie Mellon University, Machine Learning Department (2) Amazon**\n",
    "\n",
    "The predominant approach for training web navigation agents gathers human demonstrations for a set of popular websites and hand-written tasks, but it is becoming clear that human data are an inefficient resource. We develop a pipeline to facilitate Internet-scale training for agents without laborious human annotations. In the first stage, an LLM generates tasks for 150k diverse websites. In the next stage, LLM agents complete tasks and produce trajectories. In the final stage, an LLM reviews the trajectories and judges their success. Language models are competitive with human annotators, detecting and filtering out harmful content with an accuracy of 97%, generating feasible tasks with an 89% rate, and judging successful trajectories with an 82.6% accuracy. Scaling the pipeline, agents based on Llama 3.1 70B solve 16.7% of tasks for 150k sites. Training on the data generated by our pipeline is competitive with training on human demonstrations. In data-limited settings derived from Mind2Web and WebLINX, we improve Step Accuracy by up to +89.5% and +122.1% respectively for agents trained on mixtures of data from our pipeline, and human data. When training agents with all available human data from these benchmarks, agents fail to generalize to diverse real sites, and adding our data improves their generalization by +149.0% for WebLINX and +156.3% for Mind2Web. Code available at: [data-for-agents.github.io](https://data-for-agents.github.io).\n",
    "\n",
    "[website](https://data-for-agents.github.io)    |    [paper](https://arxiv.org/abs/2502.06776)    |    [data](https://huggingface.co/datasets/data-for-agents/insta-150k)\n",
    "\n",
    "---\n",
    "\n",
    "This notebook provides a demo of the InSTA pipeline for agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5479eda-927f-4489-92ef-ad9f5501093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following commands to install InSTA and prepare the environment\n",
    "\n",
    "# !docker pull brandontrabucco/insta-browser-environment\n",
    "# !docker run -p 7860:7860 -p 3000-3007:3000-3007 -t brandontrabucco/insta-browser-environment &\n",
    "# !pip install git+https://github.com/data-for-agents/insta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b25e556-2830-41ac-aff8-83dfcbff967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from insta import (\n",
    "    InstaPipeline,\n",
    "    create_demo_videos\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0cd7036-68f9-4ab9-ab8a-ec2a0befb995",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = InstaPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d47e3d9-7438-4028-a817-18b307f3861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_demo_options = [\n",
    "    {   # 0\n",
    "        \"domain\": \"sustainablewebdesign.org\",\n",
    "        \"task\": \"Retrieve a guide on reducing website carbon emissions.\"\n",
    "    },\n",
    "    {   # 1\n",
    "        \"domain\": \"statejobs.ny.gov\",\n",
    "        \"task\": \"Search for currently available jobs in the field of environmental conservation.\"\n",
    "    },\n",
    "    {   # 2\n",
    "        \"domain\": \"quanthub.com\",\n",
    "        \"task\": \"Find a research paper on quantum computing algorithms.\"\n",
    "    },\n",
    "    {   # 3\n",
    "        \"domain\": \"nameberry.com\",\n",
    "        \"task\": \"Find the most popular baby names of the past decade.\"\n",
    "    },\n",
    "    {   # 4\n",
    "        \"domain\": \"apple.es\",\n",
    "        \"task\": \"Find the technical specifications of the latest iPhone model.\"\n",
    "    },\n",
    "    {   # 5\n",
    "        \"domain\": \"agro.bayer.nl\",\n",
    "        \"task\": \"Locate information on crop protection products for wheat.\"\n",
    "    },\n",
    "    {   # 6\n",
    "        \"domain\": \"misti.mit.edu\",\n",
    "        \"task\": \"Find a course lecture on introductory computer science.\"\n",
    "    },\n",
    "    {   # 7\n",
    "        \"domain\": \"sharjahairport.ae\",\n",
    "        \"task\": \"Check the flight schedule for arrivals at Sharjah International Airport.\"\n",
    "    },\n",
    "    {   # 8\n",
    "        \"domain\": \"w.org\",\n",
    "        \"task\": \"Find documentation on how to install WordPress on a website.\"\n",
    "    },\n",
    "    {   # 9\n",
    "        \"domain\": \"visuwords.com\",\n",
    "        \"task\": \"Visualize the word relationships for \\\"artificial intelligence\\\".\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "992010e4-77a4-4a4b-a6ac-783b6ef3934c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: apple.es: 100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [05:53<00:00, 353.94s/it]\n"
     ]
    }
   ],
   "source": [
    "IDX = 4\n",
    "\n",
    "pipeline.run_pipeline(\n",
    "    dataset = [prepared_demo_options[IDX]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "995922fc-50f2-4473-80b2-d12d09624a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: apple.es: 100%|██████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:20<00:00, 20.64s/it]\n"
     ]
    }
   ],
   "source": [
    "create_demo_videos(\n",
    "    task_is_feasible_threshold = 0.0,\n",
    "    success_threshold = 0.0,\n",
    "    on_right_track_threshold = 0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74e4c7c0-0316-4395-9896-92e1eb40e7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126179e9cad7431abcca33e5c5668920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(Output(layout=Layout(grid_area='widget001')),), layout=Layout(grid_template_areas='\"w…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import Output, GridspecLayout\n",
    "from IPython import display\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "MAX_VIDEOS = 10\n",
    "\n",
    "selected_video_files = glob.glob(\n",
    "    \"data/videos/*.mp4\"\n",
    ")[:MAX_VIDEOS]\n",
    "\n",
    "height = len(selected_video_files)\n",
    "\n",
    "video_grid = GridspecLayout(\n",
    "    1, height\n",
    ")\n",
    "\n",
    "for panel_idx, video_path in enumerate(\n",
    "    selected_video_files\n",
    "):\n",
    "    \n",
    "    video_output = Output()\n",
    "    \n",
    "    with video_output:\n",
    "        \n",
    "        display.display(display.Video(\n",
    "            video_path,\n",
    "            embed = True,\n",
    "            width = 1000\n",
    "        ))\n",
    "        \n",
    "    video_grid[0, panel_idx] = video_output\n",
    "\n",
    "video_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f034f10-3fed-4251-a2da-21bf8a315693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Observation for data/videos/apple.es.mp4:\n",
      "\n",
      "iPhone 16 y iPhone 16 Plus - Especificaciones técnicas - Apple (ES) \n",
      "* [id: 13] Apple link\n",
      "* * [id: 27] Tienda link\n",
      "    * [id: 37] Menú de la tienda button\n",
      " \n",
      "    * [id: 87] Mac link\n",
      "    * [id: 97] Menú del Mac button\n",
      " \n",
      "    * [id: 165] iPad link\n",
      "    * [id: 175] Menú del iPad button\n",
      " \n",
      "    * [id: 239] iPhone link\n",
      "    * [id: 249] Menú del iPhone button\n",
      " \n",
      "    * [id: 313] Watch link\n",
      "    * [id: 323] Menú del Apple Watch button\n",
      " \n",
      "    * [id: 385] AirPods link\n",
      "    * [id: 395] Menú de los AirPods button\n",
      " \n",
      "    * [id: 437] TV y Casa link\n",
      "    * [id: 447] Menú de TV y Casa button\n",
      " \n",
      "    * [id: 505] Entretenimiento link\n",
      "    * [id: 515] Menú de entretenimiento button\n",
      " \n",
      "    * [id: 556] Accesorios link\n",
      "    * [id: 566] Menú de accesorios button\n",
      " \n",
      "    * [id: 605] Soporte link\n",
      "    * [id: 615] Menú de soporte button\n",
      "* [id: 665] Buscar en apple.com link\n",
      "* [id: 697] Bolsa link\n",
      " [id: 746] iPhone 16 link \n",
      "* [id: 755] Descripción link\n",
      "* [id: 757] Pasarse de Android al iPhone link\n",
      "* Especificaciones\n",
      " [id: 769] Comprar un iPhone 16 link \n",
      "# Especificaciones técnicas del iPhone 16\n",
      " |  | iPhone 16 | iPhone 16 Plus | | Acabado | Negro, blanco, rosa, verde azulado y azul ultramar | Diseño de aluminio | Parte delantera con Ceramic Shield de última generación | Parte trasera de vidrio tintado en masa (negro, rosa, verde azulado y azul ultramar) | Negro, blanco, rosa, verde azulado y azul ultramar | Diseño de aluminio | Parte delantera con Ceramic Shield de última generación | Parte trasera de vidrio tintado en masa (negro, rosa, verde azulado y azul ultramar) | | Capacidad [id: 809] Nota a pie de página 1 link | 128 GB | 256 GB | 512 GB | 128 GB | 256 GB | 512 GB |\n",
      "\n",
      "\n",
      "Final Action for data/videos/apple.es.mp4:\n",
      "\n",
      "## Summary\n",
      "We are currently on the iPhone 16 technical specifications webpage, and we have found the technical specifications of the latest iPhone model.\n",
      "\n",
      "## Step-by-Step Explanation\n",
      "To confirm that we have found the correct information, let's review the technical specifications table. The table lists the different models of the iPhone 16, including the iPhone 16 and iPhone 16 Plus, and their respective capacities, designs, and features.\n",
      "\n",
      "## Action\n",
      "We will stop the browser and confirm that we have found the technical specifications of the latest iPhone model.\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action_key\": \"stop\",\n",
      "    \"action_kwargs\": {\n",
      "        \"answer\": \"The technical specifications of the iPhone 16 are listed in the table, including capacity, design, and features.\"\n",
      "    },\n",
      "    \"target_element_id\": null\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "Judgment for data/videos/apple.es.mp4:\n",
      "\n",
      "Evaluating script progress towards finding iPhone 16 technical specs.\n",
      "The script has navigated to the iPhone 16 technical specifications page and is now confirming the correct information, so it is on the right track and likely to succeed.\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"task_is_feasible\": 1.0,\n",
      "    \"success\": 0.9,\n",
      "    \"on_right_track\": 1.0\n",
      "}\n",
      "```\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_video_path = selected_video_files[0]\n",
    "\n",
    "# show the final observation, action, and judgment responses:\n",
    "\n",
    "final_observation = \"data/observations/{}\".format(\n",
    "    os.path.basename(first_video_path)\n",
    "    .replace(\".mp4\", \".json\")\n",
    ")\n",
    "\n",
    "with open(final_observation, \"r\") as file:\n",
    "\n",
    "    final_observation = json.load(file)[-1]\n",
    "\n",
    "final_action = \"data/actions/{}\".format(\n",
    "    os.path.basename(first_video_path)\n",
    "    .replace(\".mp4\", \".json\")\n",
    ")\n",
    "\n",
    "with open(final_action, \"r\") as file:\n",
    "\n",
    "    final_action = json.load(file)[-1]\n",
    "\n",
    "judgment = \"data/judgments/{}\".format(\n",
    "    os.path.basename(first_video_path)\n",
    "    .replace(\".mp4\", \".json\")\n",
    ")\n",
    "\n",
    "with open(judgment, \"r\") as file:\n",
    "\n",
    "    judgment = json.load(file)\n",
    "\n",
    "print(\n",
    "    \"Final Observation for {}:\\n\\n{}\\n\\n\".format(\n",
    "        first_video_path,\n",
    "        final_observation[\"processed_text\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Final Action for {}:\\n\\n{}\\n\\n\".format(\n",
    "        first_video_path,\n",
    "        final_action[\"response\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Judgment for {}:\\n\\n{}\\n\\n\".format(\n",
    "        first_video_path,\n",
    "        judgment[\"response\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb8f1352-7aa8-4666-877e-5a6aa4a58633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06010bcca14947d2ae28cc29e0cc0f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(Output(layout=Layout(grid_area='widget001')), Output(layout=Layout(grid_area='widget0…"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import Output, GridspecLayout\n",
    "from IPython import display\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "MAX_VIDEOS = 10\n",
    "\n",
    "selected_video_files = [\n",
    "    os.path.join(\"data-backup/videos/{}.mp4\".format(x[\"domain\"]))\n",
    "    for x in prepared_demo_options\n",
    "]\n",
    "\n",
    "height = len(selected_video_files)\n",
    "\n",
    "video_grid = GridspecLayout(\n",
    "    1, height\n",
    ")\n",
    "\n",
    "for panel_idx, video_path in enumerate(\n",
    "    selected_video_files\n",
    "):\n",
    "    \n",
    "    video_output = Output()\n",
    "    \n",
    "    with video_output:\n",
    "        \n",
    "        display.display(display.Video(\n",
    "            video_path,\n",
    "            embed = True,\n",
    "            width = 1000\n",
    "        ))\n",
    "        \n",
    "    video_grid[0, panel_idx] = video_output\n",
    "\n",
    "video_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cdc59e-f16f-4d36-a395-2e7b134c26e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
