{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7dff3de",
   "metadata": {},
   "source": [
    "# InSTA: Towards Internet-Scale Training For Agents\n",
    "\n",
    "![Pipeline Overview](https://data-for-agents.github.io/static/images/pipeline_overview.png)\n",
    "\n",
    "**Brandon Trabucco (1) Gunnar Sigurdsson (2) Robinson Piramuthu (2) Ruslan Salakhutdinov (1)**\n",
    "\n",
    "**(1) Carnegie Mellon University, Machine Learning Department (2) Amazon**\n",
    "\n",
    "The predominant approach for training web navigation agents gathers human demonstrations for a set of popular websites and hand-written tasks, but it is becoming clear that human data are an inefficient resource. We develop a pipeline to facilitate Internet-scale training for agents without laborious human annotations. In the first stage, an LLM generates tasks for 150k diverse websites. In the next stage, LLM agents complete tasks and produce trajectories. In the final stage, an LLM reviews the trajectories and judges their success. Language models are competitive with human annotators, detecting and filtering out harmful content with an accuracy of 97%, generating feasible tasks with an 89% rate, and judging successful trajectories with an 82.6% accuracy. Scaling the pipeline, agents based on Llama 3.1 70B solve 16.7% of tasks for 150k sites. Training on the data generated by our pipeline is competitive with training on human demonstrations. In data-limited settings derived from Mind2Web and WebLINX, we improve Step Accuracy by up to +89.5% and +122.1% respectively for agents trained on mixtures of data from our pipeline, and human data. When training agents with all available human data from these benchmarks, agents fail to generalize to diverse real sites, and adding our data improves their generalization by +149.0% for WebLINX and +156.3% for Mind2Web. Code available at: [data-for-agents.github.io](https://data-for-agents.github.io).\n",
    "\n",
    "[website](https://data-for-agents.github.io)    |    [paper](https://arxiv.org/abs/2502.06776)    |    [data](https://huggingface.co/datasets/data-for-agents/insta-150k)\n",
    "\n",
    "---\n",
    "\n",
    "This notebook provides a demo of the InSTA pipeline for agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5479eda-927f-4489-92ef-ad9f5501093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following commands to install InSTA and prepare the environment\n",
    "\n",
    "# !docker pull brandontrabucco/insta-browser-environment\n",
    "# !docker run -p 7860:7860 -p 3000-3007:3000-3007 -t brandontrabucco/insta-browser-environment &\n",
    "# !pip install git+https://github.com/data-for-agents/insta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b25e556-2830-41ac-aff8-83dfcbff967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from insta import (\n",
    "    InstaPipeline,\n",
    "    create_demo_videos\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0cd7036-68f9-4ab9-ab8a-ec2a0befb995",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = InstaPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d47e3d9-7438-4028-a817-18b307f3861b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: research-portal.uws.ac.uk:   0%|                                   | 1/143811 [13:59<33542:37:36, 839.67s/it]\n"
     ]
    }
   ],
   "source": [
    "N = 0  # select the number of demos\n",
    "\n",
    "for data_idx, trajectory in enumerate(\n",
    "    pipeline.iter_pipeline()\n",
    "):\n",
    "\n",
    "    if data_idx >= N:\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "995922fc-50f2-4473-80b2-d12d09624a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: rubytalk.org: 100%|████████████████████████████████████████████████████████| 234/234 [01:18<00:00,  3.00it/s]\n"
     ]
    }
   ],
   "source": [
    "create_demo_videos(\n",
    "    task_is_feasible_threshold = 1.0,\n",
    "    success_threshold = 1.0,\n",
    "    on_right_track_threshold = 1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74e4c7c0-0316-4395-9896-92e1eb40e7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7060fc6785094fc987c066e094eaa2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(Output(layout=Layout(grid_area='widget001')), Output(layout=Layout(grid_area='widget0…"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import Output, GridspecLayout\n",
    "from IPython import display\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "MAX_VIDEOS = 10\n",
    "\n",
    "selected_video_files = glob.glob(\n",
    "    \"data/videos/*.mp4\"\n",
    ")[:MAX_VIDEOS]\n",
    "\n",
    "height = len(selected_video_files)\n",
    "\n",
    "video_grid = GridspecLayout(\n",
    "    1, height\n",
    ")\n",
    "\n",
    "for panel_idx, video_path in enumerate(\n",
    "    selected_video_files\n",
    "):\n",
    "    \n",
    "    video_output = Output()\n",
    "    \n",
    "    with video_output:\n",
    "        \n",
    "        display.display(display.Video(\n",
    "            video_path,\n",
    "            embed = True,\n",
    "            width = 1000\n",
    "        ))\n",
    "        \n",
    "    video_grid[0, panel_idx] = video_output\n",
    "\n",
    "video_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f034f10-3fed-4251-a2da-21bf8a315693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Observation for data/videos/apple.es.mp4:\n",
      "\n",
      "iPhone 16 y iPhone 16 Plus - Especificaciones técnicas - Apple (ES) [id: 823] iPhone 16 link \n",
      "* [id: 832] Descripción link\n",
      "* [id: 834] Pasarse de Android al iPhone link\n",
      "* Especificaciones\n",
      " [id: 846] Comprar un iPhone 16 link | Negro, blanco, rosa, verde azulado y azul ultramar | Diseño de aluminio | Parte delantera con Ceramic Shield de última generación | Parte trasera de vidrio tintado en masa (negro, rosa, verde azulado y azul ultramar) | Negro, blanco, rosa, verde azulado y azul ultramar | Diseño de aluminio | Parte delantera con Ceramic Shield de última generación | Parte trasera de vidrio tintado en masa (negro, rosa, verde azulado y azul ultramar) | | Capacidad [id: 886] Nota a pie de página 1 link | 128 GB | 256 GB | 512 GB | 128 GB | 256 GB | 512 GB | | Dimensiones y peso [id: 909] Nota a pie de página 2 link | Ancho: | 7,16 cm | Alto: | 14,76 cm | Grosor: | 0,78 cm | Peso: | 170 g | Ancho: | 7,78 cm | Alto: | 16,09 cm | Grosor: | 0,78 cm | Peso: | 199 g |\n",
      "\n",
      "\n",
      "Final Action for data/videos/apple.es.mp4:\n",
      "\n",
      "## Summary\n",
      "We are currently on the iPhone 16 technical specifications webpage, and we have found the technical specifications of the iPhone 16, including its capacity, dimensions, and weight.\n",
      "\n",
      "## Step-by-Step Explanation\n",
      "We have successfully found the technical specifications of the latest iPhone model by scrolling down the page. The specifications include the capacity (128 GB, 256 GB, 512 GB), dimensions (width, height, thickness), and weight of the iPhone 16.\n",
      "\n",
      "## Action\n",
      "We will stop the browser and provide the answer, as we have found the technical specifications of the latest iPhone model.\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action_key\": \"stop\",\n",
      "    \"action_kwargs\": {\n",
      "        \"answer\": \"The technical specifications of the iPhone 16 include: capacity (128 GB, 256 GB, 512 GB), dimensions (width: 7.16 cm, height: 14.76 cm, thickness: 0.78 cm), and weight (170 g).\"\n",
      "    },\n",
      "    \"target_element_id\": null\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "Judgment for data/videos/apple.es.mp4:\n",
      "\n",
      "Evaluating the script's progress in finding the iPhone 16's technical specifications.\n",
      "\n",
      "The script has successfully navigated to the iPhone 16 webpage, found the \"Especificaciones técnicas\" link, and scrolled down the page to find the technical specifications. The current webpage displays the technical specifications, including capacity, dimensions, and weight. \n",
      "\n",
      "The proposed next action is to stop the browser and provide the answer, as the technical specifications have been found. \n",
      "\n",
      "Here is the evaluation:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"task_is_feasible\": 1.0,\n",
      "    \"success\": 1.0,\n",
      "    \"on_right_track\": 1.0\n",
      "}\n",
      "```\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_video_path = selected_video_files[0]\n",
    "\n",
    "# show the final observation, action, and judgment responses:\n",
    "\n",
    "final_observation = \"data/observations/{}\".format(\n",
    "    os.path.basename(first_video_path)\n",
    "    .replace(\".mp4\", \".json\")\n",
    ")\n",
    "\n",
    "with open(final_observation, \"r\") as file:\n",
    "\n",
    "    final_observation = json.load(file)[-1]\n",
    "\n",
    "final_action = \"data/actions/{}\".format(\n",
    "    os.path.basename(first_video_path)\n",
    "    .replace(\".mp4\", \".json\")\n",
    ")\n",
    "\n",
    "with open(final_action, \"r\") as file:\n",
    "\n",
    "    final_action = json.load(file)[-1]\n",
    "\n",
    "judgment = \"data/judgments/{}\".format(\n",
    "    os.path.basename(first_video_path)\n",
    "    .replace(\".mp4\", \".json\")\n",
    ")\n",
    "\n",
    "with open(judgment, \"r\") as file:\n",
    "\n",
    "    judgment = json.load(file)\n",
    "\n",
    "print(\n",
    "    \"Final Observation for {}:\\n\\n{}\\n\\n\".format(\n",
    "        first_video_path,\n",
    "        final_observation[\"processed_text\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Final Action for {}:\\n\\n{}\\n\\n\".format(\n",
    "        first_video_path,\n",
    "        final_action[\"response\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Judgment for {}:\\n\\n{}\\n\\n\".format(\n",
    "        first_video_path,\n",
    "        judgment[\"response\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8f1352-7aa8-4666-877e-5a6aa4a58633",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
